# 实验笔记

## 关于preprocess的准备
* 根据opts与README.md，在data文件夹下部署了数据
* 根据https://github.com/ezeli/BUTD_model/issues/12，将MSCOCO数据集的图片平铺到了data/images下
* 根据讨论，采用了trainval 36特征
## 训练
设备：集群的一台RTX3080
开始时间：2024年3月13日，9：48，
启动train.py 3分钟后运行内存占用 3771MB，出门上英语课去了。
CPU占用在600%到1000%之间（大概6-10个核心）

### 2024年3月13日，13：38，
CPU占用在70%左右（一个核心都没占满）。
显存占用依然在3.7G左右，显卡功耗114W。
我想，是否可以通过提高batchsize，与使用data_parallel提升训练速度呢？在尝试后，以失败告终。

2024年3月13日，13：49的训练输出，可以观察到loss，val_loss都在下降。
--------------------epoch: 0
100%|█████████████████████████████████████████████████████████| 5665/5665 [1:45:31<00:00,  1.12s/it]
100%|█████████████████████████████████████████████████████████████| 250/250 [02:15<00:00,  1.84it/s]
100%|█████████████████████████████████████████████████████████████| 250/250 [05:21<00:00,  1.29s/it]
train_loss: 3.3160, train_reward: 0.0000, val_loss: 2.6779
--------------------epoch: 1
100%|█████████████████████████████████████████████████████████| 5665/5665 [1:16:59<00:00,  1.23it/s]
100%|█████████████████████████████████████████████████████████████| 250/250 [02:20<00:00,  1.78it/s]
train_loss: 2.6833, train_reward: 0.0000, val_loss: 2.4799
--------------------epoch: 2
 59%|██████████████████████████████████▊                        | 3339/5665 [49:46<22:10,  1.75it/s]

 基本上来说，两个小时一个epoch吧。

 EPOCH6起，采用128batchsize

 我决定在EPOCH2训练结束后，继续训练，但提升到batch_size到64，这大概能填满显存。

 EPOCH 6结果：train_loss: 2.2618, train_reward: 0.0000, val_loss: 2.2575

准备睡觉，让它慢慢练一晚上吧。

### 2024/3/14 下午
EPOCH 13结果：train_loss: 2.3001, train_reward: 0.0000, val_loss: 2.2166

训练一晚上，没有复现结果，怎么回事？数据预处理出现问题了吗？还是说要再等上更多EPOCH呢？
没有更多的训练时间了。

### 2024/3/14 21:49
在xe的EPOCH 13后，专为使用lr微调模式,此时loss为2.2180。
命令为
```sh
python train.py --resume checkpoint/xe/model_10_2.2180_0314-2123.pth --train_mode rl --learning_rate 4e-5  --batch_size 128
```
祈祷LOSS能有显著下降。


### 2024/3/20 22:13
在经过十次lr训练后，性能似乎不错了。
文件是model_10_4.3917_0315-1911.pth
使用该模型进行推理，基本上还挺靠谱。